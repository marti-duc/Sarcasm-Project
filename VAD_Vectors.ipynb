{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook maps every tweet to the VAD dictionary. The VAD Dictionary has almost 14,000 lemmas, each assigned a Valence, Dominance, and Arousal score. When there is a matching lemma in the tweet, it is added to each vector (valence, dominance, arousal). If the lemma appears more than once in the tweet, the values are added. For example, if'be' has a valence score of 2 and appears twice in the tweet, the valence score will be 4 for this vector. \n",
    "\n",
    "<br>\n",
    "\n",
    "The goal is to compare the Valence Vector for the Sarcastic Responses to the Valence Vector for the Sarcastic Contexts. Next, compare the Valence Vector for the Not Sarcastic Responses to the Not Valence Vector for the Sarcastic Contexts\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('Reddit/Reddit_Training2Contexts.csv', index_col=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>response</th>\n",
       "      <th>context/0</th>\n",
       "      <th>context/1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SARCASM</td>\n",
       "      <td>Yeah I mean there's only one gender anyways, w...</td>\n",
       "      <td>When gender is unknown he/him is default.</td>\n",
       "      <td>LPT: If you're worried about hurting someone's...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SARCASM</td>\n",
       "      <td>Sounds like you don't like science, you theist...</td>\n",
       "      <td>I wouldn't let that robot near me.</td>\n",
       "      <td>Promotional images for some guy's Facebook page</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SARCASM</td>\n",
       "      <td>Ofc play them in try mode, Blizzard were so ge...</td>\n",
       "      <td>And if i want to play a chimp that isn't on fr...</td>\n",
       "      <td>My friends won't play Dota2; I won't play LoL;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SARCASM</td>\n",
       "      <td>I don't understand, Reddit told me that Hillar...</td>\n",
       "      <td>+11 in PA +3 in AZ +15 in NH +9 in MI +1 in MO...</td>\n",
       "      <td>Poll: Convention boosts Clinton to 11-point le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SARCASM</td>\n",
       "      <td>yeh, they're the reigning triple premiers, why...</td>\n",
       "      <td>Live in the moment mate, it's not healthy to d...</td>\n",
       "      <td>Wayne Ludbey: Jordan Lewis has the ultimate co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4395</th>\n",
       "      <td>NOT_SARCASM</td>\n",
       "      <td>well you could've been adulting if you hadn't ...</td>\n",
       "      <td>I want to let you know that your one comment h...</td>\n",
       "      <td>Nephelim?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4396</th>\n",
       "      <td>NOT_SARCASM</td>\n",
       "      <td>Also they'll have to join the euro</td>\n",
       "      <td>A real border might be a turn off for Scottish...</td>\n",
       "      <td>I think Scotland may actually leave this time ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4397</th>\n",
       "      <td>NOT_SARCASM</td>\n",
       "      <td>plot: AI assists a cyborg in freelance investi...</td>\n",
       "      <td>Honestly, this is a good idea for a pinoy cybe...</td>\n",
       "      <td>Mag-ingat sa riding in tandem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4398</th>\n",
       "      <td>NOT_SARCASM</td>\n",
       "      <td>Some airlines proposed this but too much publi...</td>\n",
       "      <td>So a fit person should be allowed to take extr...</td>\n",
       "      <td>Not to mention the people it's carrying as well.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4399</th>\n",
       "      <td>NOT_SARCASM</td>\n",
       "      <td>Any number of corporate shill organizations ba...</td>\n",
       "      <td>Which ones are those?</td>\n",
       "      <td>He should just join one of the hundreds of con...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4400 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            label                                           response  \\\n",
       "0         SARCASM  Yeah I mean there's only one gender anyways, w...   \n",
       "1         SARCASM  Sounds like you don't like science, you theist...   \n",
       "2         SARCASM  Ofc play them in try mode, Blizzard were so ge...   \n",
       "3         SARCASM  I don't understand, Reddit told me that Hillar...   \n",
       "4         SARCASM  yeh, they're the reigning triple premiers, why...   \n",
       "...           ...                                                ...   \n",
       "4395  NOT_SARCASM  well you could've been adulting if you hadn't ...   \n",
       "4396  NOT_SARCASM                 Also they'll have to join the euro   \n",
       "4397  NOT_SARCASM  plot: AI assists a cyborg in freelance investi...   \n",
       "4398  NOT_SARCASM  Some airlines proposed this but too much publi...   \n",
       "4399  NOT_SARCASM  Any number of corporate shill organizations ba...   \n",
       "\n",
       "                                              context/0  \\\n",
       "0             When gender is unknown he/him is default.   \n",
       "1                    I wouldn't let that robot near me.   \n",
       "2     And if i want to play a chimp that isn't on fr...   \n",
       "3     +11 in PA +3 in AZ +15 in NH +9 in MI +1 in MO...   \n",
       "4     Live in the moment mate, it's not healthy to d...   \n",
       "...                                                 ...   \n",
       "4395  I want to let you know that your one comment h...   \n",
       "4396  A real border might be a turn off for Scottish...   \n",
       "4397  Honestly, this is a good idea for a pinoy cybe...   \n",
       "4398  So a fit person should be allowed to take extr...   \n",
       "4399                              Which ones are those?   \n",
       "\n",
       "                                              context/1  \n",
       "0     LPT: If you're worried about hurting someone's...  \n",
       "1       Promotional images for some guy's Facebook page  \n",
       "2     My friends won't play Dota2; I won't play LoL;...  \n",
       "3     Poll: Convention boosts Clinton to 11-point le...  \n",
       "4     Wayne Ludbey: Jordan Lewis has the ultimate co...  \n",
       "...                                                 ...  \n",
       "4395                                          Nephelim?  \n",
       "4396  I think Scotland may actually leave this time ...  \n",
       "4397                      Mag-ingat sa riding in tandem  \n",
       "4398   Not to mention the people it's carrying as well.  \n",
       "4399  He should just join one of the hundreds of con...  \n",
       "\n",
       "[4400 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "def clean_column(col):   #get rid of punctuation\n",
    "    return col.str.replace('[^\\w\\s]','')\n",
    "data[['context/1', 'context/0', 'response']] = data[['context/1', 'context/0', 'response']].apply(clean_column)\n",
    "\n",
    "columns = ['context/1','context/0','response']  #tokenize\n",
    "for column in columns:\n",
    "    data[(column+'_tokenized')] = data.apply(lambda row: nltk.word_tokenize(row[column]), axis=1) #tokenize\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "\n",
    "class LemmatizationWithPOSTagger(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def get_wordnet_pos(self,treebank_tag):\n",
    "        \"\"\"\n",
    "        return WORDNET POS compliance to WORDENT lemmatization (a,n,r,v) \n",
    "        \"\"\"\n",
    "        if treebank_tag.startswith('J'):\n",
    "            return wordnet.ADJ\n",
    "        elif treebank_tag.startswith('V'):\n",
    "            return wordnet.VERB\n",
    "        elif treebank_tag.startswith('N'):\n",
    "            return wordnet.NOUN\n",
    "        elif treebank_tag.startswith('R'):\n",
    "            return wordnet.ADV\n",
    "        else:\n",
    "            # As default pos in lemmatization is Noun\n",
    "            return wordnet.NOUN\n",
    "\n",
    "    def pos_tag(self,tokens):\n",
    "        # find the pos tagginf for each tokens [('What', 'WP'), ('can', 'MD'), ('I', 'PRP') ....\n",
    "        pos_tokens = [nltk.pos_tag(token) for token in tokens]\n",
    "\n",
    "        # lemmatization using pos tagg   \n",
    "        # convert into feature set of [('What', 'What', ['WP']), ('can', 'can', ['MD']), ... ie [original WORD, Lemmatized word, POS tag]\n",
    "#         pos_tokens = [ [(lemmatizer.lemmatize(word,self.get_wordnet_pos(pos_tag)), [pos_tag]) for (word,pos_tag) in pos] for pos in pos_tokens]\n",
    "        pos_tokens = [ [(lemmatizer.lemmatize(word,self.get_wordnet_pos(pos_tag))) for (word,pos_tag) in pos] for pos in pos_tokens]\n",
    "\n",
    "        return pos_tokens\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatization_using_pos_tagger = LemmatizationWithPOSTagger()\n",
    "\n",
    "#step 2 lemmatization using pos tagger \n",
    "\n",
    "columns = ['context/1_tokenized','context/0_tokenized','response_tokenized']\n",
    "for column in columns:\n",
    "    data[(column)] = lemmatization_using_pos_tagger.pos_tag((data[column]))#tokenize\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>response</th>\n",
       "      <th>context/0</th>\n",
       "      <th>context/1</th>\n",
       "      <th>context/1_tokenized</th>\n",
       "      <th>context/0_tokenized</th>\n",
       "      <th>response_tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NOT_SARCASM</td>\n",
       "      <td>I was elected to golf not to uh got nothing</td>\n",
       "      <td>I was elected to LEAD not to READ</td>\n",
       "      <td>Calling it a decision is pretty generous</td>\n",
       "      <td>[Calling, it, a, decision, be, pretty, generous]</td>\n",
       "      <td>[I, be, elect, to, LEAD, not, to, READ]</td>\n",
       "      <td>[I, be, elect, to, golf, not, to, uh, got, not...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NOT_SARCASM</td>\n",
       "      <td>I thought those kids were in a very bad spot T...</td>\n",
       "      <td>God damn Thai Navy SEALs and the crew that pla...</td>\n",
       "      <td>Thailand cave rescue All 12 boys coach freed l...</td>\n",
       "      <td>[Thailand, cave, rescue, All, 12, boy, coach, ...</td>\n",
       "      <td>[God, damn, Thai, Navy, SEALs, and, the, crew,...</td>\n",
       "      <td>[I, think, those, kid, be, in, a, very, bad, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NOT_SARCASM</td>\n",
       "      <td>Nothing gives off that hipster low budget star...</td>\n",
       "      <td>They have an entire spot on the Venice pier bo...</td>\n",
       "      <td>The whole thing seemed like a way to trick inv...</td>\n",
       "      <td>[The, whole, thing, seem, like, a, way, to, tr...</td>\n",
       "      <td>[They, have, an, entire, spot, on, the, Venice...</td>\n",
       "      <td>[Nothing, give, off, that, hipster, low, budge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NOT_SARCASM</td>\n",
       "      <td>A major corporation would run a kickstarter so...</td>\n",
       "      <td>Nickelodeon could Kickstart that shit The peop...</td>\n",
       "      <td>It needs the intro Outro not so much</td>\n",
       "      <td>[It, need, the, intro, Outro, not, so, much]</td>\n",
       "      <td>[Nickelodeon, could, Kickstart, that, shit, Th...</td>\n",
       "      <td>[A, major, corporation, would, run, a, kicksta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SARCASM</td>\n",
       "      <td>Yup scott accidentally added a last name to a ...</td>\n",
       "      <td>Yeah so we shouldnt hate on MatPat because he ...</td>\n",
       "      <td>To be honest the whole lore of fnaf has become...</td>\n",
       "      <td>[To, be, honest, the, whole, lore, of, fnaf, h...</td>\n",
       "      <td>[Yeah, so, we, shouldnt, hate, on, MatPat, bec...</td>\n",
       "      <td>[Yup, scott, accidentally, add, a, last, name,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         label                                           response  \\\n",
       "0  NOT_SARCASM        I was elected to golf not to uh got nothing   \n",
       "1  NOT_SARCASM  I thought those kids were in a very bad spot T...   \n",
       "2  NOT_SARCASM  Nothing gives off that hipster low budget star...   \n",
       "3  NOT_SARCASM  A major corporation would run a kickstarter so...   \n",
       "4      SARCASM  Yup scott accidentally added a last name to a ...   \n",
       "\n",
       "                                           context/0  \\\n",
       "0                  I was elected to LEAD not to READ   \n",
       "1  God damn Thai Navy SEALs and the crew that pla...   \n",
       "2  They have an entire spot on the Venice pier bo...   \n",
       "3  Nickelodeon could Kickstart that shit The peop...   \n",
       "4  Yeah so we shouldnt hate on MatPat because he ...   \n",
       "\n",
       "                                           context/1  \\\n",
       "0           Calling it a decision is pretty generous   \n",
       "1  Thailand cave rescue All 12 boys coach freed l...   \n",
       "2  The whole thing seemed like a way to trick inv...   \n",
       "3               It needs the intro Outro not so much   \n",
       "4  To be honest the whole lore of fnaf has become...   \n",
       "\n",
       "                                 context/1_tokenized  \\\n",
       "0   [Calling, it, a, decision, be, pretty, generous]   \n",
       "1  [Thailand, cave, rescue, All, 12, boy, coach, ...   \n",
       "2  [The, whole, thing, seem, like, a, way, to, tr...   \n",
       "3       [It, need, the, intro, Outro, not, so, much]   \n",
       "4  [To, be, honest, the, whole, lore, of, fnaf, h...   \n",
       "\n",
       "                                 context/0_tokenized  \\\n",
       "0            [I, be, elect, to, LEAD, not, to, READ]   \n",
       "1  [God, damn, Thai, Navy, SEALs, and, the, crew,...   \n",
       "2  [They, have, an, entire, spot, on, the, Venice...   \n",
       "3  [Nickelodeon, could, Kickstart, that, shit, Th...   \n",
       "4  [Yeah, so, we, shouldnt, hate, on, MatPat, bec...   \n",
       "\n",
       "                                  response_tokenized  \n",
       "0  [I, be, elect, to, golf, not, to, uh, got, not...  \n",
       "1  [I, think, those, kid, be, in, a, very, bad, s...  \n",
       "2  [Nothing, give, off, that, hipster, low, budge...  \n",
       "3  [A, major, corporation, would, run, a, kicksta...  \n",
       "4  [Yup, scott, accidentally, add, a, last, name,...  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAD Dictionary Contains 13915 lemmas\n"
     ]
    }
   ],
   "source": [
    "\"\"\"VAD dictionary\"\"\"\n",
    "import csv\n",
    "reader = csv.reader(open('Desktop/UPDATED_NLP_COURSE/vad1.csv'))\n",
    "\n",
    "dictionary = {}\n",
    "for row in reader:\n",
    "    key = row[1]\n",
    "    value = row[2:]\n",
    "    dictionary[key] = value\n",
    "    \n",
    "dictionary.pop('Word')      \n",
    "print('VAD Dictionary Contains', len(dictionary), 'lemmas')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vector_df is now a dataframe with 4490 columns\n"
     ]
    }
   ],
   "source": [
    "#This will create a dataframe with a column for each word found in the reponse, context1 or context0 columns\n",
    "\n",
    "vector_df = pd.DataFrame() \n",
    "def create_vector(column):\n",
    "    for row in column:\n",
    "        for token in row:\n",
    "            if token in dictionary:\n",
    "                if token not in vector_df:\n",
    "                    vector_df[token] = {}\n",
    "for column in columns:\n",
    "    create_vector(data[column]) \n",
    "\n",
    "print(\"vector_df is now a dataframe with\", len(vector_df.columns), 'columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "columnslist = vector_df.columns.tolist()\n",
    "row_by_column = np.zeros(shape=(len(data),len(columnslist))) #create 1800*4490 df\n",
    "vector_df = pd.DataFrame(row_by_column,columns=columnslist) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make 9 copies of the vector\n",
    "vector_response_valence,vector_response_arousal,vector_response_dominance = [vector_df.copy() for i in range(3)]\n",
    "vector_context0_valence,vector_context0_arousal,vector_context0_dominance = [vector_df.copy() for i in range(3)]\n",
    "vector_context1_valence,vector_context1_arousal,vector_context1_dominance = [vector_df.copy() for i in range(3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_values(text_df, vector_valence, vector_arousal,vector_dominance):   #one df has tweets, the other will have values assigned\n",
    "    for idx,row in enumerate(text_df):\n",
    "        val_vader_dict = {}\n",
    "        aro_vader_dict = {}\n",
    "        dom_vader_dict = {}\n",
    "        for token in row:\n",
    "            if token in dictionary:\n",
    "                val_value = float(dictionary[token][0])\n",
    "                aro_value = float(dictionary[token][1])\n",
    "                dom_value = float(dictionary[token][2])\n",
    "                if token not in val_vader_dict:   #if its in one, its in all\n",
    "                    val_vader_dict[token] = val_value\n",
    "                    aro_vader_dict[token] = aro_value\n",
    "                    dom_vader_dict[token] = dom_value\n",
    "                else:\n",
    "                    val_vader_dict[token] = val_vader_dict[token] + val_value\n",
    "                    aro_vader_dict[token] = aro_vader_dict[token] + aro_value\n",
    "                    dom_vader_dict[token] = dom_vader_dict[token] + dom_value\n",
    "        for key in val_vader_dict:\n",
    "            vector_valence[key][idx] = val_vader_dict[key]\n",
    "            vector_arousal[key][idx] = aro_vader_dict[key]\n",
    "            vector_dominance[key][idx] = dom_vader_dict[key]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "assign_values(data['response_tokenized'],vector_response_valence,vector_response_arousal,vector_response_dominance)\n",
    "assign_values(data['context/0_tokenized'],vector_context0_valence,vector_context0_arousal,vector_context0_dominance)\n",
    "assign_values(data['context/1_tokenized'],vector_context1_valence,vector_context1_arousal,vector_context1_dominance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4490"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vector_response_valence.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>decision</th>\n",
       "      <th>be</th>\n",
       "      <th>pretty</th>\n",
       "      <th>generous</th>\n",
       "      <th>cave</th>\n",
       "      <th>rescue</th>\n",
       "      <th>boy</th>\n",
       "      <th>coach</th>\n",
       "      <th>free</th>\n",
       "      <th>late</th>\n",
       "      <th>...</th>\n",
       "      <th>dibs</th>\n",
       "      <th>veritable</th>\n",
       "      <th>overlap</th>\n",
       "      <th>sheepdog</th>\n",
       "      <th>negotiator</th>\n",
       "      <th>depressing</th>\n",
       "      <th>zoo</th>\n",
       "      <th>evolutionary</th>\n",
       "      <th>biologist</th>\n",
       "      <th>prospective</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>12.36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1795</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1796</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1797</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1798</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1799</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1800 rows Ã— 4490 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      decision     be  pretty  generous  cave  rescue  boy  coach  free  late  \\\n",
       "0          0.0   6.18     0.0       0.0   0.0     0.0  0.0    0.0   0.0   0.0   \n",
       "1          0.0  12.36     0.0       0.0   0.0     0.0  0.0    0.0   0.0   0.0   \n",
       "2          0.0   0.00     0.0       0.0   0.0     0.0  0.0    0.0   0.0   0.0   \n",
       "3          0.0   6.18     0.0       0.0   0.0     0.0  0.0    0.0   0.0   0.0   \n",
       "4          0.0   6.18     0.0       0.0   0.0     0.0  0.0    0.0   0.0   0.0   \n",
       "...        ...    ...     ...       ...   ...     ...  ...    ...   ...   ...   \n",
       "1795       0.0   0.00     0.0       0.0   0.0     0.0  0.0    0.0   0.0   0.0   \n",
       "1796       0.0   0.00     0.0       0.0   0.0     0.0  0.0    0.0   0.0   0.0   \n",
       "1797       0.0   0.00     0.0       0.0   0.0     0.0  0.0    0.0   0.0   0.0   \n",
       "1798       0.0   6.18     0.0       0.0   0.0     0.0  0.0    0.0   0.0   0.0   \n",
       "1799       0.0   0.00     0.0       0.0   0.0     0.0  0.0    0.0   0.0   0.0   \n",
       "\n",
       "      ...  dibs  veritable  overlap  sheepdog  negotiator  depressing  zoo  \\\n",
       "0     ...   0.0        0.0      0.0       0.0         0.0         0.0  0.0   \n",
       "1     ...   0.0        0.0      0.0       0.0         0.0         0.0  0.0   \n",
       "2     ...   0.0        0.0      0.0       0.0         0.0         0.0  0.0   \n",
       "3     ...   0.0        0.0      0.0       0.0         0.0         0.0  0.0   \n",
       "4     ...   0.0        0.0      0.0       0.0         0.0         0.0  0.0   \n",
       "...   ...   ...        ...      ...       ...         ...         ...  ...   \n",
       "1795  ...   0.0        0.0      0.0       0.0         0.0         0.0  0.0   \n",
       "1796  ...   0.0        0.0      0.0       0.0         0.0         0.0  0.0   \n",
       "1797  ...   0.0        0.0      0.0       0.0         0.0         0.0  0.0   \n",
       "1798  ...   0.0        0.0      0.0       0.0         0.0         0.0  0.0   \n",
       "1799  ...   0.0        0.0      0.0       0.0         0.0         0.0  0.0   \n",
       "\n",
       "      evolutionary  biologist  prospective  \n",
       "0              0.0        0.0         0.00  \n",
       "1              0.0        0.0         0.00  \n",
       "2              0.0        0.0         0.00  \n",
       "3              0.0        0.0         0.00  \n",
       "4              0.0        0.0         0.00  \n",
       "...            ...        ...          ...  \n",
       "1795           0.0        0.0         0.00  \n",
       "1796           0.0        0.0         0.00  \n",
       "1797           0.0        0.0         0.00  \n",
       "1798           0.0        0.0         5.76  \n",
       "1799           0.0        0.0         0.00  \n",
       "\n",
       "[1800 rows x 4490 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_response_valence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>decision</th>\n",
       "      <th>be</th>\n",
       "      <th>pretty</th>\n",
       "      <th>generous</th>\n",
       "      <th>cave</th>\n",
       "      <th>rescue</th>\n",
       "      <th>boy</th>\n",
       "      <th>coach</th>\n",
       "      <th>free</th>\n",
       "      <th>late</th>\n",
       "      <th>...</th>\n",
       "      <th>dibs</th>\n",
       "      <th>veritable</th>\n",
       "      <th>overlap</th>\n",
       "      <th>sheepdog</th>\n",
       "      <th>negotiator</th>\n",
       "      <th>depressing</th>\n",
       "      <th>zoo</th>\n",
       "      <th>evolutionary</th>\n",
       "      <th>biologist</th>\n",
       "      <th>prospective</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>18.54</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1795</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1796</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1797</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1798</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1799</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1800 rows Ã— 4490 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      decision     be  pretty  generous  cave  rescue  boy  coach  free  late  \\\n",
       "0          0.0   6.18     0.0       0.0   0.0     0.0  0.0    0.0   0.0   0.0   \n",
       "1          0.0  18.54     0.0       0.0   0.0     0.0  0.0    0.0   0.0   0.0   \n",
       "2          0.0   6.18     0.0       0.0   0.0     0.0  0.0    0.0   0.0   0.0   \n",
       "3          0.0   0.00     0.0       0.0   0.0     0.0  0.0    0.0   0.0   0.0   \n",
       "4          0.0   6.18     0.0       0.0   0.0     0.0  0.0    0.0   0.0   0.0   \n",
       "...        ...    ...     ...       ...   ...     ...  ...    ...   ...   ...   \n",
       "1795       0.0   0.00     0.0       0.0   0.0     0.0  0.0    0.0   0.0   0.0   \n",
       "1796       0.0   0.00     0.0       0.0   0.0     0.0  0.0    0.0   0.0   0.0   \n",
       "1797       0.0   0.00     0.0       0.0   0.0     0.0  0.0    0.0   0.0   0.0   \n",
       "1798       0.0   0.00     0.0       0.0   0.0     0.0  0.0    0.0   0.0   0.0   \n",
       "1799       0.0   6.18     0.0       0.0   0.0     0.0  0.0    0.0   0.0   0.0   \n",
       "\n",
       "      ...  dibs  veritable  overlap  sheepdog  negotiator  depressing  zoo  \\\n",
       "0     ...   0.0        0.0      0.0       0.0         0.0         0.0  0.0   \n",
       "1     ...   0.0        0.0      0.0       0.0         0.0         0.0  0.0   \n",
       "2     ...   0.0        0.0      0.0       0.0         0.0         0.0  0.0   \n",
       "3     ...   0.0        0.0      0.0       0.0         0.0         0.0  0.0   \n",
       "4     ...   0.0        0.0      0.0       0.0         0.0         0.0  0.0   \n",
       "...   ...   ...        ...      ...       ...         ...         ...  ...   \n",
       "1795  ...   0.0        0.0      0.0       0.0         0.0         0.0  0.0   \n",
       "1796  ...   0.0        0.0      0.0       0.0         0.0         0.0  0.0   \n",
       "1797  ...   0.0        0.0      0.0       0.0         0.0         0.0  0.0   \n",
       "1798  ...   0.0        0.0      0.0       0.0         0.0         0.0  0.0   \n",
       "1799  ...   0.0        0.0      0.0       0.0         0.0         0.0  0.0   \n",
       "\n",
       "      evolutionary  biologist  prospective  \n",
       "0              0.0        0.0          0.0  \n",
       "1              0.0        0.0          0.0  \n",
       "2              0.0        0.0          0.0  \n",
       "3              0.0        0.0          0.0  \n",
       "4              0.0        0.0          0.0  \n",
       "...            ...        ...          ...  \n",
       "1795           0.0        0.0          0.0  \n",
       "1796           0.0        0.0          0.0  \n",
       "1797           0.0        0.0          0.0  \n",
       "1798           0.0        0.0          0.0  \n",
       "1799           0.0        0.0          0.0  \n",
       "\n",
       "[1800 rows x 4490 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_context0_valence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_response_valence['tweet_label']= data['label'] #append the label column\n",
    "vector_response_arousal['tweet_label']= data['label'] #append the label column\n",
    "vector_response_dominance['tweet_label']= data['label'] #append the label column\n",
    "\n",
    "vector_context0_valence['tweet_label']= data['label'] #append the label column\n",
    "vector_context0_arousal['tweet_label']= data['label'] #append the label column\n",
    "vector_context0_dominance['tweet_label']= data['label'] #append the label column\n",
    "\n",
    "\n",
    "vector_context1_valence['tweet_label']= data['label'] #append the label column\n",
    "vector_context1_arousal['tweet_label']= data['label'] #append the label column\n",
    "vector_context1_dominance['tweet_label']= data['label'] #append the label column\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_valence_sarc = vector_response_valence[vector_response_valence[\"tweet_label\"]==\"SARCASM\"].copy()\n",
    "response_arousal_sarc = vector_response_arousal[vector_response_arousal[\"tweet_label\"]==\"SARCASM\"].copy()\n",
    "response_dominance_sarc = vector_response_dominance[vector_response_dominance[\"tweet_label\"]==\"SARCASM\"].copy()\n",
    "\n",
    "response_valence_notsarc = vector_response_valence[vector_response_valence[\"tweet_label\"]==\"NOT_SARCASM\"].copy()\n",
    "response_arousal_notsarc = vector_response_arousal[vector_response_arousal[\"tweet_label\"]==\"NOT_SARCASM\"].copy()\n",
    "response_dominance_notsarc = vector_response_dominance[vector_response_dominance[\"tweet_label\"]==\"NOT_SARCASM\"].copy()\n",
    "\n",
    "\n",
    "context0_valence_sarc = vector_context0_valence[vector_context0_valence[\"tweet_label\"]==\"SARCASM\"].copy()\n",
    "context0_arousal_sarc = vector_context0_arousal[vector_context0_arousal[\"tweet_label\"]==\"SARCASM\"].copy()\n",
    "context0_dominance_sarc = vector_context0_dominance[vector_context0_dominance[\"tweet_label\"]==\"SARCASM\"].copy()\n",
    "\n",
    "context0_valence_notsarc = vector_context0_valence[vector_context0_valence[\"tweet_label\"]==\"NOT_SARCASM\"].copy()\n",
    "context0_arousal_notsarc = vector_context0_arousal[vector_context0_arousal[\"tweet_label\"]==\"NOT_SARCASM\"].copy()\n",
    "context0_dominance_notsarc = vector_context0_dominance[vector_context0_dominance[\"tweet_label\"]==\"NOT_SARCASM\"].copy()\n",
    "\n",
    "\n",
    "context1_valence_sarc = vector_context1_valence[vector_context0_valence[\"tweet_label\"]==\"SARCASM\"].copy()\n",
    "context1_arousal_sarc = vector_context1_arousal[vector_context0_arousal[\"tweet_label\"]==\"SARCASM\"].copy()\n",
    "context1_dominance_sarc = vector_context1_dominance[vector_context0_dominance[\"tweet_label\"]==\"SARCASM\"].copy()\n",
    "\n",
    "context1_valence_notsarc = vector_context1_valence[vector_context0_valence[\"tweet_label\"]==\"NOT_SARCASM\"].copy()\n",
    "context1_arousal_notsarc = vector_context1_arousal[vector_context0_arousal[\"tweet_label\"]==\"NOT_SARCASM\"].copy()\n",
    "context1_dominance_notsarc = vector_context1_dominance[vector_context0_dominance[\"tweet_label\"]==\"NOT_SARCASM\"].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALENCE SARCASTIC - RESPONSE & CONTEXT 0\n",
      "\n",
      "4       0.513365\n",
      "6       0.066922\n",
      "9      -0.001058\n",
      "11     -0.000422\n",
      "12     -0.000487\n",
      "          ...   \n",
      "1793    0.116657\n",
      "1795         NaN\n",
      "1797   -0.000816\n",
      "1798   -0.000877\n",
      "1799   -0.000737\n",
      "Length: 900, dtype: float64\n",
      "\n",
      "0.1589732230361785\n",
      "\n",
      "VALENCE NOT SARCASTIC - RESPONSE & CONTEXT 0\n",
      "\n",
      "0       0.825202\n",
      "1       0.377769\n",
      "2       0.124362\n",
      "3       0.395440\n",
      "5      -0.001119\n",
      "          ...   \n",
      "1786   -0.000907\n",
      "1790    0.326219\n",
      "1792   -0.000315\n",
      "1794    0.418991\n",
      "1796   -0.000736\n",
      "Length: 900, dtype: float64\n",
      "\n",
      "0.15217070029435123\n"
     ]
    }
   ],
   "source": [
    "rvs =response_valence_sarc.corrwith(context0_valence_sarc, axis = 1, method = 'pearson') \n",
    "print(\"VALENCE SARCASTIC - RESPONSE & CONTEXT 0\")\n",
    "print()\n",
    "print(rvs)\n",
    "print()\n",
    "print(rvs.mean(axis=0))\n",
    "print()\n",
    "\n",
    "rvns = response_valence_notsarc.corrwith(context0_valence_notsarc, axis = 1, method = 'pearson') \n",
    "print(\"VALENCE NOT SARCASTIC - RESPONSE & CONTEXT 0\")\n",
    "print()\n",
    "print(rvns)\n",
    "print()\n",
    "print(rvns.mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOMINANCE SARCASTIC - RESPONSE & CONTEXT 0\n",
      "\n",
      "4       0.413302\n",
      "6       0.061027\n",
      "9      -0.001080\n",
      "11     -0.000435\n",
      "12     -0.000496\n",
      "          ...   \n",
      "1793    0.100078\n",
      "1795         NaN\n",
      "1797   -0.000857\n",
      "1798   -0.000925\n",
      "1799   -0.000761\n",
      "Length: 900, dtype: float64\n",
      "\n",
      "0.15148968414873049\n",
      "\n",
      "DOMINANCE NOT SARCASTIC - RESPONSE & CONTEXT 0\n",
      "\n",
      "0       0.799235\n",
      "1       0.353741\n",
      "2       0.103885\n",
      "3       0.437330\n",
      "5      -0.001133\n",
      "          ...   \n",
      "1786   -0.000913\n",
      "1790    0.403467\n",
      "1792   -0.000315\n",
      "1794    0.407785\n",
      "1796   -0.000764\n",
      "Length: 900, dtype: float64\n",
      "\n",
      "0.14787701204021936\n"
     ]
    }
   ],
   "source": [
    "rds = response_dominance_sarc.corrwith(context0_dominance_sarc, axis = 1, method = 'pearson') \n",
    "print(\"DOMINANCE SARCASTIC - RESPONSE & CONTEXT 0\")\n",
    "print()\n",
    "print(rds)\n",
    "print()\n",
    "print(rds.mean(axis=0))\n",
    "print()\n",
    "\n",
    "rdns = response_dominance_notsarc.corrwith(context0_dominance_notsarc, axis = 1, method = 'pearson') \n",
    "print(\"DOMINANCE NOT SARCASTIC - RESPONSE & CONTEXT 0\")\n",
    "print()\n",
    "print(rdns)\n",
    "print()\n",
    "print(rdns.mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AROUSAL SARCASTIC - RESPONSE & CONTEXT 0\n",
      "\n",
      "4       0.363098\n",
      "6       0.043259\n",
      "9      -0.001071\n",
      "11     -0.000442\n",
      "12     -0.000489\n",
      "          ...   \n",
      "1793    0.073634\n",
      "1795         NaN\n",
      "1797   -0.000815\n",
      "1798   -0.000917\n",
      "1799   -0.000762\n",
      "Length: 900, dtype: float64\n",
      "\n",
      "0.144011414200297\n",
      "\n",
      "AROUSAL NOT SARCASTIC - RESPONSE & CONTEXT 0\n",
      "\n",
      "0       0.816939\n",
      "1       0.299081\n",
      "2       0.107093\n",
      "3       0.379875\n",
      "5      -0.001121\n",
      "          ...   \n",
      "1786   -0.000916\n",
      "1790    0.220933\n",
      "1792   -0.000306\n",
      "1794    0.410509\n",
      "1796   -0.000752\n",
      "Length: 900, dtype: float64\n",
      "\n",
      "0.14030036439189694\n"
     ]
    }
   ],
   "source": [
    "ras = response_arousal_sarc.corrwith(context0_arousal_sarc, axis = 1, method = 'pearson') \n",
    "print(\"AROUSAL SARCASTIC - RESPONSE & CONTEXT 0\")\n",
    "print()\n",
    "print(ras)\n",
    "print()\n",
    "print(ras.mean(axis=0))\n",
    "print()\n",
    "\n",
    "rans = response_arousal_notsarc.corrwith(context0_dominance_notsarc, axis = 1, method = 'pearson') \n",
    "print(\"AROUSAL NOT SARCASTIC - RESPONSE & CONTEXT 0\")\n",
    "print()\n",
    "print(rans)\n",
    "print()\n",
    "print(rans.mean(axis=0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import csv \n",
    "import pandas\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context/0</th>\n",
       "      <th>response</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@USER If your child isn't named Barron ... #Be...</td>\n",
       "      <td>@USER @USER @USER I don't get this .. obviousl...</td>\n",
       "      <td>SARCASM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@USER @USER having to make up excuses of why y...</td>\n",
       "      <td>@USER @USER trying to protest about . Talking ...</td>\n",
       "      <td>SARCASM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@USER I ’ ll remember to not support you at th...</td>\n",
       "      <td>@USER @USER @USER He makes an insane about of ...</td>\n",
       "      <td>SARCASM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@USER But not half as stupid as Schiff looks ....</td>\n",
       "      <td>@USER @USER Meanwhile Trump won't even release...</td>\n",
       "      <td>SARCASM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@USER They already did . Obama said many times...</td>\n",
       "      <td>@USER @USER Pretty Sure the Anti-Lincoln Crowd...</td>\n",
       "      <td>SARCASM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           context/0  \\\n",
       "0  @USER If your child isn't named Barron ... #Be...   \n",
       "1  @USER @USER having to make up excuses of why y...   \n",
       "2  @USER I ’ ll remember to not support you at th...   \n",
       "3  @USER But not half as stupid as Schiff looks ....   \n",
       "4  @USER They already did . Obama said many times...   \n",
       "\n",
       "                                            response    label  \n",
       "0  @USER @USER @USER I don't get this .. obviousl...  SARCASM  \n",
       "1  @USER @USER trying to protest about . Talking ...  SARCASM  \n",
       "2  @USER @USER @USER He makes an insane about of ...  SARCASM  \n",
       "3  @USER @USER Meanwhile Trump won't even release...  SARCASM  \n",
       "4  @USER @USER Pretty Sure the Anti-Lincoln Crowd...  SARCASM  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('Desktop/Sarcasm_Corr/Twitter_Training2Contexts.csv')\n",
    "pd.options.display.max_columns = None\n",
    "df = data[['context/0','response','label']].copy()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"### Vader \"\"\"\n",
    "def vader(sentence):\n",
    "    from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "    vader = SentimentIntensityAnalyzer()\n",
    "    score = vader.polarity_scores(sentence)\n",
    "    return score\n",
    "\n",
    "# creating lists to keep pos, neu, neg, and compound scores --- later to be used to create a dataframe\n",
    "\n",
    "\n",
    "# extracting vader scores for each entry in the data\n",
    "# (we're not using context yet.)\n",
    "# note that the compound score is rescaled to the [0,1] range\n",
    "# some classiifers don't take negative values (e.g., MultinomialNB)\n",
    "\n",
    "\n",
    "def vader_scores(df):\n",
    "    vs_compound = []\n",
    "    vs_pos = []\n",
    "    vs_neu = []\n",
    "    vs_neg = []\n",
    "    for row in df:\n",
    "        score = vader(row)\n",
    "        neg = float(score['neg'])\n",
    "        vs_neg.append(neg)\n",
    "        neu =float(score['neu'])\n",
    "        vs_neu.append(neu)\n",
    "        pos =float(score['pos'])\n",
    "        vs_pos.append(pos)\n",
    "        compound = float((score['compound']+1)/2) # rescaling to the [0,1] range\n",
    "        vs_compound.append(compound)\n",
    "    return vs_compound, vs_pos, vs_neu, vs_neg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvs_compound, cvs_pos, cvs_neu, cvs_neg = vader_scores(df['context/0'])  #compute vader scores for context/0\n",
    "\n",
    "df = df.assign(cntx_vader_neu = cvs_neu, cntx_vader_pos = cvs_pos, cntx_vader_neg = cvs_neg, cntx_vader_compound = cvs_compound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "rvs_compound, rvs_pos, rvs_neu, rvs_neg = vader_scores(df['response'])  #compute vader scores for response\n",
    "df = df.assign(resp_vader_neu = rvs_neu, resp_vader_pos = rvs_pos, resp_vader_neg = rvs_neg, resp_vader_compound = rvs_compound)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df[df[\"label\"]==\"SARCASM\"].copy()  #Divide DATA by label \n",
    "df2 = df[df[\"label\"]==\"NOT_SARCASM\"].copy() #Divide DATA by label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare Response to Context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "def correlation_calc(response, context, a):   #Pearson\n",
    "    r_list = response.tolist()\n",
    "    c_list = context.tolist()\n",
    "    correlation,p_value = stats.pearsonr(r_list,c_list)\n",
    "    return a, correlation\n",
    "\n",
    "def correlation_calcSpearman(response, context, a):   #Spearman\n",
    "    r_list = response.tolist()\n",
    "    c_list = context.tolist()\n",
    "    correlation,p_value = stats.spearmanr(r_list,c_list)\n",
    "    return a, correlation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the Correlation of the Vader Compound Scores for Sarcastic Responses and the Sarcastic Context that preceeded them. Compute the correlation of the Non-Sarcastic Responses to their corresponding contexts. \n",
    "<br>\n",
    "Continue doing this for all Vader Values (Negative, Positive, Neutral, and Compound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson\n",
      "Compound\n",
      "('Sarcasm Vader Compound Correlation: ', 0.07605447332942038)\n",
      "('Not Sarcasm Vader Compound Correlation: ', 0.2749945641751499)\n",
      "\n",
      "Positive\n",
      "('Sarcasm Vader Positive Correlation: ', 0.0872712783097193)\n",
      "('Not Sarcasm Vader Positive Correlation: ', 0.28833031334280174)\n",
      "\n",
      "Negative\n",
      "('Sarcasm Vader Negative Correlation: ', 0.13894980844486815)\n",
      "('Not Sarcasm Vader Negative Correlation: ', 0.222379548228165)\n",
      "\n",
      "Neutral\n",
      "('Sarcasm Vader Neutral Correlation: ', 0.15577725670092682)\n",
      "('Not Sarcasm Vader Neutral Correlation: ', 0.2080424030509918)\n",
      "\n",
      "\n",
      "Spearman\n",
      "Compound\n",
      "('Sarcasm Vader Compound Correlation: ', 0.07210957829895888)\n",
      "('Not Sarcasm Vader Compound Correlation: ', 0.30928573118032054)\n",
      "\n",
      "Positive\n",
      "('Sarcasm Vader Positive Correlation: ', 0.0689342310373311)\n",
      "('Not Sarcasm Vader Positive Correlation: ', 0.25313823098823024)\n",
      "\n",
      "Negative\n",
      "('Sarcasm Vader Negative Correlation: ', 0.11009089507947474)\n",
      "('Not Sarcasm Vader Negative Correlation: ', 0.23755676598443232)\n",
      "\n",
      "Neutral\n",
      "('Sarcasm Vader Neutral Correlation: ', 0.14751447533423853)\n",
      "('Not Sarcasm Vader Neutral Correlation: ', 0.19501226569300106)\n"
     ]
    }
   ],
   "source": [
    "print('Pearson')\n",
    "print('Compound')\n",
    "print(correlation_calc(df1['resp_vader_compound'], df1['cntx_vader_compound'], \"Sarcasm Vader Compound Correlation: \"))\n",
    "print(correlation_calc(df2['resp_vader_compound'], df2['cntx_vader_compound'], \"Not Sarcasm Vader Compound Correlation: \"))\n",
    "print()\n",
    "print('Positive')\n",
    "print(correlation_calc(df1['resp_vader_pos'], df1['cntx_vader_pos'], \"Sarcasm Vader Positive Correlation: \"))\n",
    "print(correlation_calc(df2['resp_vader_pos'], df2['cntx_vader_pos'], \"Not Sarcasm Vader Positive Correlation: \"))\n",
    "print()\n",
    "print('Negative')\n",
    "print(correlation_calc(df1['resp_vader_neg'], df1['cntx_vader_neg'], \"Sarcasm Vader Negative Correlation: \"))\n",
    "print(correlation_calc(df2['resp_vader_neg'], df2['cntx_vader_neg'], \"Not Sarcasm Vader Negative Correlation: \"))\n",
    "print()\n",
    "print('Neutral')\n",
    "print(correlation_calc(df1['resp_vader_neu'], df1['cntx_vader_neu'], \"Sarcasm Vader Neutral Correlation: \"))\n",
    "print(correlation_calc(df2['resp_vader_neu'], df2['cntx_vader_neu'], \"Not Sarcasm Vader Neutral Correlation: \"))\n",
    "\n",
    "\n",
    "print()\n",
    "print()\n",
    "\n",
    "print('Spearman')\n",
    "print('Compound')\n",
    "print(correlation_calcSpearman(df1['resp_vader_compound'], df1['cntx_vader_compound'], \"Sarcasm Vader Compound Correlation: \"))\n",
    "print(correlation_calcSpearman(df2['resp_vader_compound'], df2['cntx_vader_compound'], \"Not Sarcasm Vader Compound Correlation: \"))\n",
    "print()\n",
    "print('Positive')\n",
    "print(correlation_calcSpearman(df1['resp_vader_pos'], df1['cntx_vader_pos'], \"Sarcasm Vader Positive Correlation: \"))\n",
    "print(correlation_calcSpearman(df2['resp_vader_pos'], df2['cntx_vader_pos'], \"Not Sarcasm Vader Positive Correlation: \"))\n",
    "print()\n",
    "print('Negative')\n",
    "print(correlation_calcSpearman(df1['resp_vader_neg'], df1['cntx_vader_neg'], \"Sarcasm Vader Negative Correlation: \"))\n",
    "print(correlation_calcSpearman(df2['resp_vader_neg'], df2['cntx_vader_neg'], \"Not Sarcasm Vader Negative Correlation: \"))\n",
    "print()\n",
    "print('Neutral')\n",
    "print(correlation_calcSpearman(df1['resp_vader_neu'], df1['cntx_vader_neu'], \"Sarcasm Vader Neutral Correlation: \"))\n",
    "print(correlation_calcSpearman(df2['resp_vader_neu'], df2['cntx_vader_neu'], \"Not Sarcasm Vader Neutral Correlation: \"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VAD\n",
    "\n",
    "Valence/Arousal/Dominance\n",
    "\n",
    "Using Warriner et al.'s dictionary for norms of valence, arousal, and dominance (VAD) for 13,915 English lemmas, we compute the average VAD scores for each tweet. \n",
    "\n",
    "Next, we compute the correlation between the valence/arousal/dominance score of the sarcastic responses and their corresponding preceeding contexts, and compare this to the correlation between the correlation of the VAD score of the non-sarcastic responses & contexts. We hypothesize that the Not-Sarcastic responses will have a higher correlation with their preceeding context since Sarcasm can be marked by a change in emotion.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Vad will pull all the words that are found in the dictionary, then sum up all the scores, and divide by # of words that matched dictionary entry\n",
    "import pandas as pd\n",
    "import nltk\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"### Dataframe\n",
    "Columns: Context & Response\n",
    "\"\"\"\n",
    "\n",
    "df.loc[:,'tokenized_context']  = df.loc[:,'context/0'].str.replace('[^\\w\\s]','')  #get rid of punctuation\n",
    "df['tokenized_response']  = df.loc[:,'response'].str.replace('[^\\w\\s]','')  #get rid of punctuation\n",
    "\n",
    "\"\"\"tokenize context & response\"\"\"\n",
    "df.loc[:,'tokenized_context'] = df.apply(lambda row: nltk.word_tokenize(row['tokenized_context']), axis=1) #tokenize\n",
    "df.loc[:,'tokenized_response'] = df.apply(lambda row: nltk.word_tokenize(row['tokenized_response']), axis=1) #tokenize\n",
    "\n",
    "\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "class LemmatizationWithPOSTagger(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def get_wordnet_pos(self,treebank_tag):\n",
    "        \"\"\"\n",
    "        return WORDNET POS compliance to WORDENT lemmatization (a,n,r,v) \n",
    "        \"\"\"\n",
    "        if treebank_tag.startswith('J'):\n",
    "            return wordnet.ADJ\n",
    "        elif treebank_tag.startswith('V'):\n",
    "            return wordnet.VERB\n",
    "        elif treebank_tag.startswith('N'):\n",
    "            return wordnet.NOUN\n",
    "        elif treebank_tag.startswith('R'):\n",
    "            return wordnet.ADV\n",
    "        else:\n",
    "            # As default pos in lemmatization is Noun\n",
    "            return wordnet.NOUN\n",
    "\n",
    "    def pos_tag(self,tokens):\n",
    "        # find the pos tagginf for each tokens [('What', 'WP'), ('can', 'MD'), ('I', 'PRP') ....\n",
    "        pos_tokens = [nltk.pos_tag(token) for token in tokens]\n",
    "\n",
    "        # lemmatization using pos tagg   \n",
    "        # convert into feature set of [('What', 'What', ['WP']), ('can', 'can', ['MD']), ... ie [original WORD, Lemmatized word, POS tag]\n",
    "        pos_tokens = [ [(lemmatizer.lemmatize(word,self.get_wordnet_pos(pos_tag))) for (word,pos_tag) in pos] for pos in pos_tokens]\n",
    "        #pos_tokens = [ [(lemmatizer.lemmatize(word,self.get_wordnet_pos(pos_tag)), [pos_tag]) for (word,pos_tag) in pos] for pos in pos_tokens]\n",
    "\n",
    "        return pos_tokens\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatization_using_pos_tagger = LemmatizationWithPOSTagger()\n",
    "\n",
    "#step 2 lemmatization\n",
    "\n",
    "df.loc[:,'lemma_response'] = lemmatization_using_pos_tagger.pos_tag((df.loc[:,'tokenized_response'])) #response lemma\n",
    "df.loc[:,'lemma_context'] = lemmatization_using_pos_tagger.pos_tag((df.loc[:,'tokenized_context'])) #context lemma\n",
    "\n",
    "\n",
    "\"\"\"VAD dictionary\"\"\"\n",
    "import csv\n",
    "reader = csv.reader(open('Desktop/UPDATED_NLP_COURSE/vad1.csv'))\n",
    "\n",
    "d = {}\n",
    "for row in reader:\n",
    "    key = row[1]\n",
    "    value = row[2:]\n",
    "    d[key] = value\n",
    "    \n",
    "d.pop('Word')          \n",
    "\n",
    "\n",
    "\"\"\" CHECK LEMMAS AGAINST VAD DICTIONARY\"\"\"\n",
    "\n",
    "\"\"\"response\"\"\"\n",
    "\n",
    "list_totals = [[(list(map(float,d[token]))) for token in row if token in d] for row in df['lemma_response'].array]\n",
    "\n",
    "def find_sum(x):\n",
    "    total = [[num[x] for num in l]for l in list_totals]\n",
    "    full_list = []\n",
    "    for i in total:\n",
    "        if len(i) != 0:\n",
    "            full_list.append(i)\n",
    "        else:\n",
    "            i = [5.0,5.0,5.0]    #if there is a tweet that has nothing, assign average value\n",
    "            full_list.append(i)\n",
    "    average = [((sum(x))/(len(x))) for x in full_list]     #sum of all values divided by how many there were\n",
    "    return average\n",
    "\n",
    "\n",
    "\"\"\"Response\"\"\"\n",
    "vr_total = find_sum(0)\n",
    "ar_total = find_sum(1)\n",
    "dr_total = find_sum(2)\n",
    "\n",
    "df.loc[:,'valence_response'] = vr_total\n",
    "df.loc[:,'arousal_response'] = ar_total\n",
    "df.loc[:,'dominance_response'] = dr_total\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"Context\"\"\"\n",
    "\n",
    "list_totals = [[(list(map(float,d[token]))) for token in row if token in d] for row in df['lemma_context'].array]\n",
    "\n",
    "\n",
    "vc_total = find_sum(0)\n",
    "ac_total = find_sum(1)\n",
    "dc_total = find_sum(2)\n",
    "\n",
    "\n",
    "df.loc[:,'valence_context'] = vc_total\n",
    "df.loc[:,'arousal_context'] = ac_total\n",
    "df.loc[:,'dominance_context'] = dc_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Divide data by label again \n",
    "df3 = df[df[\"label\"]==\"SARCASM\"].copy()  #Divide DATA by label\n",
    "df4 = df[df[\"label\"]==\"NOT_SARCASM\"].copy() #Divide DATA by label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valence\n",
      "('Sarcasm Valence Correlation', 0.14586568593344873)\n",
      "('Not Sarcasm Valence Correlation', 0.3009481608205475)\n",
      "\n",
      "Dominance\n",
      "('Sarcasm Dominance Correlation', 0.1341486111329201)\n",
      "('Not Sarcasm Dominance Correlation', 0.20535444999434416)\n",
      "\n",
      "Arousal\n",
      "('Sarcasm Arousal Correlation', 0.12180082280460452)\n",
      "('Not Sarcasm Arousal Correlation', 0.13527132448249019)\n"
     ]
    }
   ],
   "source": [
    "print(\"Valence\")\n",
    "print(correlation_calc(df3['valence_response'], df3['valence_context'], \"Sarcasm Valence Correlation\"))\n",
    "print(correlation_calc(df4['valence_response'], df4['valence_context'], \"Not Sarcasm Valence Correlation\"))\n",
    "print()\n",
    "print(\"Dominance\")\n",
    "print(correlation_calc(df3['dominance_response'], df3['dominance_context'], \"Sarcasm Dominance Correlation\"))\n",
    "print(correlation_calc(df4['dominance_response'], df4['dominance_context'], \"Not Sarcasm Dominance Correlation\"))\n",
    "print()\n",
    "print(\"Arousal\")\n",
    "print(correlation_calc(df3['arousal_response'], df3['arousal_context'], \"Sarcasm Arousal Correlation\"))\n",
    "print(correlation_calc(df4['arousal_response'], df4['arousal_context'], \"Not Sarcasm Arousal Correlation\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIWC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv \n",
    "from liwc import Liwc\n",
    "df5 = data[['context/0','response','label']].copy()\n",
    "\n",
    "df5.loc[:,'tokenized_context']  = df5.loc[:,'context/0'].str.replace('[^\\w\\s]','')  #get rid of punctuation\n",
    "df5.loc[:,'tokenized_response']  = df5.loc[:,'response'].str.replace('[^\\w\\s]','')  #get rid of punctuation\n",
    "\n",
    "\n",
    "\"\"\"tokenize context & response\"\"\"\n",
    "df5.loc[:,'tokenized_context'] = df5.apply(lambda row: nltk.word_tokenize(row['tokenized_context']), axis=1) #tokenize\n",
    "df5.loc[:,'tokenized_response'] = df5.apply(lambda row: nltk.word_tokenize(row['tokenized_response']), axis=1) #tokenize\n",
    "\n",
    "\n",
    "lwc = Liwc(\"Desktop/UPDATED_NLP_COURSE/liwc_dictionaries_shared/LIWC2007_English100131.dic\") #liwc dictionary\n",
    "\n",
    "\n",
    "def liwc_parse(data):    #count which categories appear in each tweet & how many times\n",
    "    liwcresults =[]\n",
    "    for token in data:  #response scores\n",
    "        results = (lwc.parse(token))\n",
    "        liwcresults.append(results)\n",
    "    return liwcresults\n",
    "\n",
    "liwc_results = liwc_parse(df5.loc[:,'tokenized_response'])\n",
    "\n",
    "def liwc_unique_keys(data):   #collect all field names\n",
    "    liwc_keys = []\n",
    "    for key_val in range(len(data)):\n",
    "        for key in data[key_val].keys():\n",
    "            if key not in liwc_keys:\n",
    "                liwc_keys.append(key)\n",
    "    return liwc_keys\n",
    "\n",
    "liwc_keys = liwc_unique_keys(liwc_results)\n",
    "\n",
    "\n",
    "#look at each category in range 3,000, if the value is not in the list of keys, append new key. \n",
    "\n",
    "with open('liwc_feature_chart_response.csv', 'w') as csv_file:  \n",
    "    dict_writer = csv.DictWriter(csv_file, liwc_keys)     #liwc keys will be column heasders   \n",
    "    writer = csv.writer(csv_file)\n",
    "    dict_writer.writeheader()\n",
    "    dict_writer.writerows(liwc_results)      #liwc results will be the rows\n",
    "    \n",
    "liwcdata = pd.read_csv(\"liwc_feature_chart_response.csv\")   #dataframe of liwc feeatures\n",
    "df5 = pd.concat([liwcdata, df5], axis=1, sort=False)   #combine dataframes\n",
    "df5.fillna(0, inplace=True)  #put zeroes wherever there are no values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_same = {'context/0', 'response', 'label', 'tokenized_context', 'tokenized_response','time_resp',\n",
    " 'relativ_resp',\n",
    " 'funct_resp',\n",
    " 'pronoun_resp',\n",
    " 'ipron_resp',\n",
    " 'adverb_resp',\n",
    " 'cogmech_resp',\n",
    " 'excl_resp',\n",
    " 'leisure_resp',\n",
    " 'conj_resp',\n",
    " 'incl_resp',\n",
    " 'verb_resp',\n",
    " 'past_resp',\n",
    " 'social_resp',\n",
    " 'ppron_resp',\n",
    " 'i_resp',\n",
    " 'cause_resp',\n",
    " 'humans_resp',\n",
    " 'certain_resp',\n",
    " 'achieve_resp',\n",
    " 'preps_resp',\n",
    " 'tentat_resp',\n",
    " 'space_resp',\n",
    " 'affect_resp',\n",
    " 'filler_resp',\n",
    " 'posemo_resp',\n",
    " 'present_resp',\n",
    " 'they_resp',\n",
    " 'shehe_resp',\n",
    " 'negemo_resp',\n",
    " 'anger_resp',\n",
    " 'quant_resp',\n",
    " 'auxverb_resp',\n",
    " 'article_resp',\n",
    " 'insight_resp',\n",
    " 'work_resp',\n",
    " 'you_resp',\n",
    " 'motion_resp',\n",
    " 'discrep_resp',\n",
    " 'assent_resp',\n",
    " 'negate_resp',\n",
    " 'inhib_resp',\n",
    " 'home_resp',\n",
    " 'percept_resp',\n",
    " 'hear_resp',\n",
    " 'anx_resp',\n",
    " 'sad_resp',\n",
    " 'see_resp',\n",
    " 'money_resp',\n",
    " 'bio_resp',\n",
    " 'health_resp',\n",
    " 'sexual_resp',\n",
    " 'nonfl_resp',\n",
    " 'future_resp',\n",
    " 'swear_resp',\n",
    " 'ingest_resp',\n",
    " 'feel_resp',\n",
    " 'number_resp',\n",
    " 'body_resp',\n",
    " 'relig_resp',\n",
    " 'family_resp',\n",
    " 'we_resp',\n",
    " 'death_resp',\n",
    " 'friend_resp'}\n",
    "df5.columns = ['{}{}'.format(c, '' if c in keep_same else '_cntx') for c in df5.columns] #add cntx prefix to determine which features belong to contexg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = df5.drop(['context/0', 'response','tokenized_context','tokenized_response'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6 = df5[df5[\"label\"]==\"SARCASM\"].copy()  #Divide DATA by label\n",
    "df7 = df5[df5[\"label\"]==\"NOT_SARCASM\"].copy() #Divide DATA by label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "j =df1.iloc[:, :64] #Sarcasm Context\n",
    "h =df1.iloc[:,64 :-1] #Sarcasm Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cntx_vader_compound_resp_cntx_cntx</th>\n",
       "      <th>cntx_vader_neg_resp_cntx_cntx</th>\n",
       "      <th>cntx_vader_neu_resp_cntx_cntx</th>\n",
       "      <th>cntx_vader_pos_resp_cntx_cntx</th>\n",
       "      <th>context/0</th>\n",
       "      <th>label</th>\n",
       "      <th>resp_vader_compound_resp_cntx_cntx</th>\n",
       "      <th>resp_vader_neg_resp_cntx_cntx</th>\n",
       "      <th>resp_vader_neu_resp_cntx_cntx</th>\n",
       "      <th>resp_vader_pos_resp_cntx_cntx</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.30625</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.832</td>\n",
       "      <td>0.000</td>\n",
       "      <td>@USER If your child isn't named Barron ... #Be...</td>\n",
       "      <td>SARCASM</td>\n",
       "      <td>0.87530</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.796</td>\n",
       "      <td>0.204</td>\n",
       "      <td>@USER @USER @USER I don't get this .. obviousl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.50000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>@USER @USER having to make up excuses of why y...</td>\n",
       "      <td>SARCASM</td>\n",
       "      <td>0.11985</td>\n",
       "      <td>0.256</td>\n",
       "      <td>0.744</td>\n",
       "      <td>0.000</td>\n",
       "      <td>@USER @USER trying to protest about . Talking ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.34555</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.816</td>\n",
       "      <td>0.000</td>\n",
       "      <td>@USER I ’ ll remember to not support you at th...</td>\n",
       "      <td>SARCASM</td>\n",
       "      <td>0.27130</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.824</td>\n",
       "      <td>0.000</td>\n",
       "      <td>@USER @USER @USER He makes an insane about of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.92570</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.708</td>\n",
       "      <td>0.253</td>\n",
       "      <td>@USER But not half as stupid as Schiff looks ....</td>\n",
       "      <td>SARCASM</td>\n",
       "      <td>0.24470</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.870</td>\n",
       "      <td>0.000</td>\n",
       "      <td>@USER @USER Meanwhile Trump won't even release...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.39885</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.841</td>\n",
       "      <td>0.058</td>\n",
       "      <td>@USER They already did . Obama said many times...</td>\n",
       "      <td>SARCASM</td>\n",
       "      <td>0.83525</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.807</td>\n",
       "      <td>0.193</td>\n",
       "      <td>@USER @USER Pretty Sure the Anti-Lincoln Crowd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2495</th>\n",
       "      <td>0.50000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>@USER @USER @USER I misspoke . Have read up on...</td>\n",
       "      <td>SARCASM</td>\n",
       "      <td>0.36915</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.892</td>\n",
       "      <td>0.000</td>\n",
       "      <td>She's dangerous &amp; self serving , but as an Ame...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2496</th>\n",
       "      <td>0.26165</td>\n",
       "      <td>0.279</td>\n",
       "      <td>0.721</td>\n",
       "      <td>0.000</td>\n",
       "      <td>@USER @USER Shame on u for justifying the poli...</td>\n",
       "      <td>SARCASM</td>\n",
       "      <td>0.51985</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.183</td>\n",
       "      <td>@USER @USER I can't even say \" shame on you \" ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2497</th>\n",
       "      <td>0.36225</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.919</td>\n",
       "      <td>0.000</td>\n",
       "      <td>@USER @USER You're = you are . Your = belongs ...</td>\n",
       "      <td>SARCASM</td>\n",
       "      <td>0.22885</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.743</td>\n",
       "      <td>0.082</td>\n",
       "      <td>@USER @USER @USER So if someone was to murder ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2498</th>\n",
       "      <td>0.50000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>#Russia , #Pakistan &amp; #China to hold 3 - way c...</td>\n",
       "      <td>SARCASM</td>\n",
       "      <td>0.07595</td>\n",
       "      <td>0.353</td>\n",
       "      <td>0.647</td>\n",
       "      <td>0.000</td>\n",
       "      <td>This trilateral consultations aim to form a re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499</th>\n",
       "      <td>0.39885</td>\n",
       "      <td>0.159</td>\n",
       "      <td>0.721</td>\n",
       "      <td>0.120</td>\n",
       "      <td>@USER @USER @USER #Fakenews is like ' lock her...</td>\n",
       "      <td>SARCASM</td>\n",
       "      <td>0.69425</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.145</td>\n",
       "      <td>@USER @USER @USER LOL you seem to forget that ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2500 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      cntx_vader_compound_resp_cntx_cntx  cntx_vader_neg_resp_cntx_cntx  \\\n",
       "0                                0.30625                          0.168   \n",
       "1                                0.50000                          0.000   \n",
       "2                                0.34555                          0.184   \n",
       "3                                0.92570                          0.039   \n",
       "4                                0.39885                          0.100   \n",
       "...                                  ...                            ...   \n",
       "2495                             0.50000                          0.000   \n",
       "2496                             0.26165                          0.279   \n",
       "2497                             0.36225                          0.081   \n",
       "2498                             0.50000                          0.000   \n",
       "2499                             0.39885                          0.159   \n",
       "\n",
       "      cntx_vader_neu_resp_cntx_cntx  cntx_vader_pos_resp_cntx_cntx  \\\n",
       "0                             0.832                          0.000   \n",
       "1                             1.000                          0.000   \n",
       "2                             0.816                          0.000   \n",
       "3                             0.708                          0.253   \n",
       "4                             0.841                          0.058   \n",
       "...                             ...                            ...   \n",
       "2495                          1.000                          0.000   \n",
       "2496                          0.721                          0.000   \n",
       "2497                          0.919                          0.000   \n",
       "2498                          1.000                          0.000   \n",
       "2499                          0.721                          0.120   \n",
       "\n",
       "                                              context/0    label  \\\n",
       "0     @USER If your child isn't named Barron ... #Be...  SARCASM   \n",
       "1     @USER @USER having to make up excuses of why y...  SARCASM   \n",
       "2     @USER I ’ ll remember to not support you at th...  SARCASM   \n",
       "3     @USER But not half as stupid as Schiff looks ....  SARCASM   \n",
       "4     @USER They already did . Obama said many times...  SARCASM   \n",
       "...                                                 ...      ...   \n",
       "2495  @USER @USER @USER I misspoke . Have read up on...  SARCASM   \n",
       "2496  @USER @USER Shame on u for justifying the poli...  SARCASM   \n",
       "2497  @USER @USER You're = you are . Your = belongs ...  SARCASM   \n",
       "2498  #Russia , #Pakistan & #China to hold 3 - way c...  SARCASM   \n",
       "2499  @USER @USER @USER #Fakenews is like ' lock her...  SARCASM   \n",
       "\n",
       "      resp_vader_compound_resp_cntx_cntx  resp_vader_neg_resp_cntx_cntx  \\\n",
       "0                                0.87530                          0.000   \n",
       "1                                0.11985                          0.256   \n",
       "2                                0.27130                          0.176   \n",
       "3                                0.24470                          0.130   \n",
       "4                                0.83525                          0.000   \n",
       "...                                  ...                            ...   \n",
       "2495                             0.36915                          0.108   \n",
       "2496                             0.51985                          0.172   \n",
       "2497                             0.22885                          0.175   \n",
       "2498                             0.07595                          0.353   \n",
       "2499                             0.69425                          0.078   \n",
       "\n",
       "      resp_vader_neu_resp_cntx_cntx  resp_vader_pos_resp_cntx_cntx  \\\n",
       "0                             0.796                          0.204   \n",
       "1                             0.744                          0.000   \n",
       "2                             0.824                          0.000   \n",
       "3                             0.870                          0.000   \n",
       "4                             0.807                          0.193   \n",
       "...                             ...                            ...   \n",
       "2495                          0.892                          0.000   \n",
       "2496                          0.645                          0.183   \n",
       "2497                          0.743                          0.082   \n",
       "2498                          0.647                          0.000   \n",
       "2499                          0.778                          0.145   \n",
       "\n",
       "                                               response  \n",
       "0     @USER @USER @USER I don't get this .. obviousl...  \n",
       "1     @USER @USER trying to protest about . Talking ...  \n",
       "2     @USER @USER @USER He makes an insane about of ...  \n",
       "3     @USER @USER Meanwhile Trump won't even release...  \n",
       "4     @USER @USER Pretty Sure the Anti-Lincoln Crowd...  \n",
       "...                                                 ...  \n",
       "2495  She's dangerous & self serving , but as an Ame...  \n",
       "2496  @USER @USER I can't even say \" shame on you \" ...  \n",
       "2497  @USER @USER @USER So if someone was to murder ...  \n",
       "2498  This trilateral consultations aim to form a re...  \n",
       "2499  @USER @USER @USER LOL you seem to forget that ...  \n",
       "\n",
       "[2500 rows x 11 columns]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = h.reindex(sorted(h.columns), axis=1)\n",
    "j = j.reindex(sorted(j.columns), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('achieve_resp', 'achieve_cntx', 0.08596522186430626)\n",
      "('adverb_resp', 'adverb_cntx', 0.08531259704593028)\n",
      "('affect_resp', 'affect_cntx', 0.08709781440329778)\n",
      "('anger_resp', 'anger_cntx', 0.10625037751469493)\n",
      "('anx_resp', 'anx_cntx', 0.041087704286221806)\n",
      "('article_resp', 'article_cntx', 0.05632156887423635)\n",
      "('assent_resp', 'assent_cntx', -0.038399515854432124)\n",
      "('auxverb_resp', 'auxverb_cntx', 0.16595676987654373)\n",
      "('bio_resp', 'bio_cntx', 0.09700002330000784)\n",
      "('body_resp', 'body_cntx', 0.06101402152986163)\n",
      "('cause_resp', 'cause_cntx', 0.008483045490866755)\n",
      "('certain_resp', 'certain_cntx', -0.0009506283670423291)\n",
      "('cogmech_resp', 'cogmech_cntx', 0.04978660740880248)\n",
      "('conj_resp', 'conj_cntx', -0.014211437486800878)\n",
      "('death_resp', 'death_cntx', 0.09729936234894491)\n",
      "('discrep_resp', 'discrep_cntx', 0.024179798420093566)\n",
      "('excl_resp', 'excl_cntx', -0.013357967814571894)\n",
      "('family_resp', 'family_cntx', 0.05039095683494532)\n",
      "('feel_resp', 'feel_cntx', 0.030187006337216896)\n",
      "('filler_resp', 'filler_cntx', 0.010274056144519754)\n",
      "('friend_resp', 'friend_cntx', 0.10842124840415421)\n",
      "('funct_resp', 'funct_cntx', 0.12660008577769322)\n",
      "('future_resp', 'future_cntx', 0.07292917419934009)\n",
      "('health_resp', 'health_cntx', 0.15534164487665597)\n",
      "('hear_resp', 'hear_cntx', -0.048360214774647595)\n",
      "('home_resp', 'home_cntx', 0.054028397603836015)\n",
      "('humans_resp', 'humans_cntx', 0.10761145235698341)\n",
      "('i_resp', 'i_cntx', -0.0032762454123702357)\n",
      "('incl_resp', 'incl_cntx', 0.027786013562757995)\n",
      "('ingest_resp', 'ingest_cntx', 0.11634708702099858)\n",
      "('inhib_resp', 'inhib_cntx', 0.0606863315731144)\n",
      "('insight_resp', 'insight_cntx', -0.0028465900128434203)\n",
      "('ipron_resp', 'ipron_cntx', 0.008427962816252197)\n",
      "('leisure_resp', 'leisure_cntx', 0.13157546073416387)\n",
      "('money_resp', 'money_cntx', 0.174799155614523)\n",
      "('motion_resp', 'motion_cntx', 0.09229434986318565)\n",
      "('negate_resp', 'negate_cntx', 0.01548851820301337)\n",
      "('negemo_resp', 'negemo_cntx', 0.1486441981284189)\n",
      "('nonfl_resp', 'nonfl_cntx', -0.02592548633045238)\n",
      "('number_resp', 'number_cntx', 0.0069711620761836665)\n",
      "('past_resp', 'past_cntx', 0.040498089179949806)\n",
      "('percept_resp', 'percept_cntx', 0.023210682963096294)\n",
      "('posemo_resp', 'posemo_cntx', 0.024248521364042)\n",
      "('ppron_resp', 'ppron_cntx', 0.03184386555286663)\n",
      "('preps_resp', 'preps_cntx', 0.07343474328502339)\n",
      "('present_resp', 'present_cntx', 0.07637257243366269)\n",
      "('pronoun_resp', 'pronoun_cntx', 0.05543520661048105)\n",
      "('quant_resp', 'quant_cntx', 0.07709411759753704)\n",
      "('relativ_resp', 'relativ_cntx', 0.007190833088909141)\n",
      "('relig_resp', 'relig_cntx', 0.26519269012518937)\n",
      "('sad_resp', 'sad_cntx', 0.1262603816394891)\n",
      "('see_resp', 'see_cntx', 0.0944093415055386)\n",
      "('sexual_resp', 'sexual_cntx', 0.07007344696332235)\n",
      "('shehe_resp', 'shehe_cntx', 0.11559937040682106)\n",
      "('social_resp', 'social_cntx', 0.07958760657623841)\n",
      "('space_resp', 'space_cntx', -0.00014154243576736808)\n",
      "('swear_resp', 'swear_cntx', 0.042222810096860526)\n",
      "('tentat_resp', 'tentat_cntx', 0.039705105336124924)\n",
      "('they_resp', 'they_cntx', 0.08131896717945633)\n",
      "('time_resp', 'time_cntx', 0.0007542195846858106)\n",
      "('verb_resp', 'verb_cntx', 0.12012061028973142)\n",
      "('we_resp', 'we_cntx', 0.012663398176252519)\n",
      "('work_resp', 'work_cntx', 0.13252919896158818)\n",
      "('you_resp', 'you_cntx', 0.028513972119603825)\n"
     ]
    }
   ],
   "source": [
    "#Sarcasm\n",
    "\n",
    "Sarcasm_Scores_List = []\n",
    "for i in range(len(h.columns)):\n",
    "    r_list = h.iloc[:,i].tolist()\n",
    "    c_list = j.iloc[:,i].tolist()\n",
    "    correlation, p_value = stats.pearsonr(r_list,c_list)\n",
    "    print((h.columns[i],j.columns[i],correlation))\n",
    "    Sarcasm_Scores_List.append((correlation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "k =df2.iloc[:, :64] #NotSarcasm context\n",
    "m =df2.iloc[:,64 :-1] #NotSarcasm response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "achieve_resp achieve_cntx 0.07145373930128096\n",
      "adverb_resp adverb_cntx 0.0520418147155224\n",
      "affect_resp affect_cntx 0.08734424883723413\n",
      "anger_resp anger_cntx 0.07277417162018122\n",
      "anx_resp anx_cntx 0.07586829248759333\n",
      "article_resp article_cntx 0.08514027692952233\n",
      "assent_resp assent_cntx 0.04161970206990138\n",
      "auxverb_resp auxverb_cntx 0.09013935118686361\n",
      "bio_resp bio_cntx 0.1467246416716215\n",
      "body_resp body_cntx 0.10095073400456936\n",
      "cause_resp cause_cntx 0.03910743840639916\n",
      "certain_resp certain_cntx 0.0509487056494122\n",
      "cogmech_resp cogmech_cntx 0.12885291122826198\n",
      "conj_resp conj_cntx 0.08840081091221613\n",
      "death_resp death_cntx 0.06737583210186694\n",
      "discrep_resp discrep_cntx 0.00934146220533316\n",
      "excl_resp excl_cntx 0.0807508010721035\n",
      "family_resp family_cntx 0.038098585022822234\n",
      "feel_resp feel_cntx 0.014433955821640906\n",
      "filler_resp filler_cntx 0.01982373351227297\n",
      "friend_resp friend_cntx 0.08091835183769447\n",
      "funct_resp funct_cntx 0.09686464576550413\n",
      "future_resp future_cntx 0.014296753952200284\n",
      "health_resp health_cntx 0.10288510314197326\n",
      "hear_resp hear_cntx 0.06630831648491864\n",
      "home_resp home_cntx 0.016060939811206924\n",
      "humans_resp humans_cntx 0.1207991468392648\n",
      "i_resp i_cntx 0.10001624022072962\n",
      "incl_resp incl_cntx 0.05071051303014427\n",
      "ingest_resp ingest_cntx 0.15753154076587458\n",
      "inhib_resp inhib_cntx 0.024654337801222177\n",
      "insight_resp insight_cntx 0.0939012124206576\n",
      "ipron_resp ipron_cntx 0.10483676596294052\n",
      "leisure_resp leisure_cntx 0.1276171206732629\n",
      "money_resp money_cntx 0.30877627932141094\n",
      "motion_resp motion_cntx -0.004206122329560757\n",
      "negate_resp negate_cntx 0.061136858912424305\n",
      "negemo_resp negemo_cntx 0.1466773990760584\n",
      "nonfl_resp nonfl_cntx 0.11924467850602012\n",
      "number_resp number_cntx 0.04055274628190853\n",
      "past_resp past_cntx 0.10036685504382495\n",
      "percept_resp percept_cntx -0.004750782271891279\n",
      "posemo_resp posemo_cntx 0.08352316968614537\n",
      "ppron_resp ppron_cntx 0.09864726118131037\n",
      "preps_resp preps_cntx 0.10478444880448323\n",
      "present_resp present_cntx 0.12905054489959153\n",
      "pronoun_resp pronoun_cntx 0.09855398360165026\n",
      "quant_resp quant_cntx 0.03500678191414645\n",
      "relativ_resp relativ_cntx 0.053123548320763686\n",
      "relig_resp relig_cntx 0.20353735918773772\n",
      "sad_resp sad_cntx 0.014871061395283826\n",
      "see_resp see_cntx -0.054947809527399374\n",
      "sexual_resp sexual_cntx 0.07913944279555726\n",
      "shehe_resp shehe_cntx 0.14377839277449422\n",
      "social_resp social_cntx 0.16602387824345072\n",
      "space_resp space_cntx 0.03014896174529675\n",
      "swear_resp swear_cntx 0.049936730034088404\n",
      "tentat_resp tentat_cntx -0.0037070648838537466\n",
      "they_resp they_cntx 0.011125693094321223\n",
      "time_resp time_cntx 0.06790989595303291\n",
      "verb_resp verb_cntx 0.08202120237179142\n",
      "we_resp we_cntx 0.10697551691908587\n",
      "work_resp work_cntx 0.19258768420097297\n",
      "you_resp you_cntx 0.15358695757041185\n"
     ]
    }
   ],
   "source": [
    "#Not Sarcasm\n",
    "k = k.reindex(sorted(k.columns), axis=1)\n",
    "m = m.reindex(sorted(m.columns), axis=1)\n",
    "\n",
    "for i in range(len(m.columns)):\n",
    "    r_list = m.iloc[:,i].tolist()\n",
    "    c_list = k.iloc[:,i].tolist()\n",
    "    correlation, p_value = stats.pearsonr(r_list,c_list)\n",
    "    print(m.columns[i],k.columns[i],correlation)\n",
    "    Not_Sarcasm_Scores_List.append((correlation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NotSarcasm Average 0.06027429415156402\n",
      "\n",
      "Sarcasm Average 0.06149014526623917\n"
     ]
    }
   ],
   "source": [
    "def Average(lst): \n",
    "    return sum(lst) / len(lst)\n",
    "\n",
    "print(\"NotSarcasm Average\", (Average(Not_Sarcasm_Scores_List)))\n",
    "print()\n",
    "print(\"Sarcasm Average\", (Average(Sarcasm_Scores_List)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation_calc(response, context, a):   #Pearson\n",
    "    r_list = response.tolist()\n",
    "    c_list = context.tolist()\n",
    "    correlation,p_value = stats.pearsonr(r_list,c_list)\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

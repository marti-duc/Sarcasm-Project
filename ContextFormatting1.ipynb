{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The current file has a thread of up to 12 contexts leading up to the tweet( labeled 'response'). Currently, context/0 is the beginning of the thread, context/1 is the second tweet of the thread, so on and so forth. \n",
    "\n",
    "<br>\n",
    "\n",
    "The formatting in this notebook will allow us to take the **last** two tweets from the thread, the ones that immediately precede the response. Context/1 will now be the context that starts the thread, Context/0 will be the one that comes next, and finally the response. We will remove all other contexts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# data = pd.read_csv(\"Reddit/reddit_test_label.csv\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = [\"Original_Reddit_Training.csv\",\n",
    "             \"reddit_test_label.csv\",\n",
    "             \"twitter_test_label.csv\",\n",
    "             \"twitter_training.csv\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatted_data(file):\n",
    "    data = pd.read_csv(filename)\n",
    "    new_data = data[['label','response']].copy()      #keep a separate DataFrame with label & response (append later)\n",
    "    new_data['context/0'],new_data['context/1'] = '',''\n",
    "    if 'id' in data.columns:\n",
    "        data = data.drop(['id'],axis =1)\n",
    "    data = data.drop(['label','response'], axis =1)   #id is only available for test set\n",
    "    data = data[data.columns[::-1]]   #reverse order of columns so that the most recent tweets are first\n",
    "    data.fillna(0,inplace = True)             # fill all \"NaN\" columns with 0's\n",
    "    \n",
    "    tweet_range = len(data)\n",
    "    context_range = len(data.columns)\n",
    "    \n",
    "    for tweet in range(tweet_range):                  #iterate over every row  \n",
    "        stored_contexts = []                   #store the context for each row in this list\n",
    "        for context in range(context_range):              #iterate over every column \n",
    "            current_context = data.iloc[tweet,context]    #locate row,column\n",
    "            if current_context != 0:                       #if the context is not '0', save it in the list\n",
    "                stored_contexts.append(current_context)\n",
    "        new_data.loc[tweet,'context/0':] = stored_contexts[:2]    #only take the first two contexts from your list\n",
    "    return(new_data)\n",
    "    \n",
    "# new_data = formatted_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in filenames:\n",
    "    new_data = formatted_data(file)\n",
    "    new_data.to_csv('formatted_'+file)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
